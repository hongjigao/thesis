\chapter{Introduction}

Post-Hartree--Fock (post-HF) electronic structure methods are essential for reaching quantitative accuracy in molecular systems' energy and properties, yet their practical reach is often limited by the cost of manipulating large operators and high-dimensional tensors. In modern implementations, this limitation is not solely a matter of floating-point operations: memory footprint, data movement, and unfavorable scaling in the dominant contractions frequently determine feasibility. A common observation across correlation methods is that the key objects are rarely ``generic dense.'' They typically exhibit \emph{structured sparsity} and \emph{structured compressibility} induced by physical locality, screening, and the organization of electronic degrees of freedom. The central aim of this dissertation is to turn these latent regularities into concrete algorithmic gains by designing hierarchical compression techniques that reduce the leading-order time and memory costs while retaining controlled accuracy.

Hierarchical matrices provide a particularly suitable framework for this goal because they interpolate between two extremes that are both unsatisfactory in many chemical settings. Pure sparse-matrix treatments assume that a large fraction of entries are exactly zero (or can be set to zero without consequence), and they therefore operate only on the remaining nonzeros. This is highly effective when the underlying operator truly induces sparsity. However, for many operators and tensors in electronic structure, aggressively zeroing small entries is too blunt: entries may be individually small but collectively important, and truncating them entrywise can destroy delicate cancellations or bias energy differences. At the other extreme, dense representations avoid approximation but quickly become memory- and bandwidth-bound as system size grows. Hierarchical matrices occupy the middle ground and should be viewed as a \emph{structure-aware sparse representation}: the matrix is sparse at the level of blocks (most blocks are not stored densely), but rather than discarding entire regions or entries, one replaces selected blocks by low-rank surrogates whose error is locally controlled. In other words, hierarchical matrices treat many chemically relevant objects as ``sparse, but not sparse enough to be treated as strictly sparse'' and exploit additional distributional regularities---such as concentration near a diagonal band, within a localized region, or in a small principal corner---to compress the remainder in a principled way.

Concretely, hierarchical matrix formats recursively partition the index sets into a multilevel cluster tree and thereby induce a block partition of the matrix. Near-field blocks (or blocks in regions of high information density) are kept explicitly, often still sparse or moderately dense depending on the application. Far-field blocks (or blocks in regions where information is diffuse) are approximated by low-rank factorizations. Classical H-matrices already yield substantial reductions in storage and matrix--vector multiplication by exploiting this blockwise low rank. The H$^2$ variant strengthens the representation further by introducing \emph{nested bases}: low-dimensional subspaces are shared across multiple blocks and reused across hierarchy levels. This nested structure is crucial when the same operator must be applied repeatedly inside iterative solvers or correlation pipelines, because it amortizes the cost of basis construction and reduces both memory and application complexity under mild rank-growth assumptions. Importantly, hierarchical matrices do not impose a single global rank or a single global notion of ``importance.'' They provide a language to encode heterogeneity: different parts of the matrix can be represented at different resolutions and with different ranks, guided by local error tolerances and local structural cues.

These properties have made hierarchical techniques broadly relevant in computational chemistry, where central objects naturally exhibit locality and screening. A prominent example is the four-index electron--repulsion integral (ERI) tensor, which can be reshaped into an $N^2\times N^2$ matrix (with $N$ the number of one-electron basis functions) indexed by basis-function pairs. In localized orbital or atomic-orbital bases, ERIs display strong near-field structure: interactions among nearby orbital pairs are comparatively strong and must be represented accurately, while interactions between well-separated groups are often compressible and admit low-rank descriptions. Hierarchical representations exploit exactly this separation, enabling reduced-memory integral storage and accelerating the construction and application of Coulomb- and Fock-like intermediates. More generally, hierarchical methods exemplify a guiding principle that is central to this dissertation: global algorithmic improvements follow from local, quantifiable structure, provided that the data layout, the approximation format, and the computational kernels are designed together so that the structure is exposed and reused across scales.

The focus of this dissertation is on hierarchical compression techniques for two representative post-HF bottlenecks that embody two \emph{different} kinds of structure. The first bottleneck arises in configuration-interaction (CI) approaches for strongly correlated systems, where the size of the coefficient tensor (or its matricizations) becomes memory-limiting as active spaces grow. The second bottleneck arises in perturbative correlation methods such as second-order M{\o}ller--Plesset theory (MP2), where the ERIs dominate both storage and contraction cost. While both objects can be viewed through the lens of large matrices (via unfoldings or reshaping), their compressibility is governed by different organizing principles: CI coefficients are primarily structured by excitation patterns and wavefunction weight distribution, whereas ERIs are primarily structured by spatial locality. A central message that emerges from the two works integrated here is that \emph{the best hierarchical format is problem-dependent}: one should not expect a single partitioning strategy (e.g., diagonal-centric admissibility) to be optimal for all post-HF objects.

To motivate the wavefunction side, recall that truncated CI methods represent the correlated state as a linear combination of determinants. In practice, the coefficient object is not merely a vector; it is frequently manipulated through structured decompositions, and a particularly informative organization is obtained by grouping determinants into $\alpha$- and $\beta$-spin strings. This yields a coefficient matrix $C$ whose rows index $\alpha$-strings and columns index $\beta$-strings. Empirically, such matrices often exhibit a striking nonuniformity: a relatively small subset of configurations carries most of the wavefunction weight, and under suitable orderings this nonuniformity manifests as a \emph{corner-dominant} pattern in $C$, where the most significant entries concentrate near a principal corner and decay away from it. This pattern is neither classical sparsity (exact zeros) nor the type of diagonal dominance that standard hierarchical formats implicitly privilege. It is instead an anisotropic concentration of information, suggesting that the hierarchy itself should be aligned with the corner where the signal resides.

The first major contribution of the dissertation therefore develops a \emph{corner-hierarchical} representation and the associated compression algorithm CHACI (CH-based approximated configuration interaction). The key design decision is to replace a ``uniform'' or ``diagonal-first'' partition by a hierarchy that recursively refines the corner region where information density is highest. Within this structure, CHACI performs blockwise compression and chooses between dense storage and truncated SVD (TSVD) representations on a per-block basis, guided by the principle that a block should be stored in the form that yields the most retained wavefunction information per unit memory at the target tolerance. A crucial practical ingredient is a data-reordering step: rows and columns are sorted by their $\ell_2$ norms so that large-magnitude rows and columns move toward the privileged corner, intensifying the corner concentration that the hierarchy is designed to exploit. Another key ingredient is \emph{rank adaptivity}: rather than imposing a single global rank (which wastes degrees of freedom in unimportant regions and starves important regions), CHACI selects ranks locally according to an information-density criterion derived from singular values and storage costs, and it allows blocks to remain dense when low-rank representation is not beneficial. Because CI coefficients must also satisfy global constraints (e.g., normalization) and because truncation error can redistribute weight across blocks, CHACI further incorporates blockwise normalization procedures that stabilize the compressed representation and mitigate artificial population transfer that would occur under a single global renormalization. The net effect is a compression strategy that is tailored to the observed geometry of information in CI tensors: it aims to capture more signal per stored parameter than global low-rank factorizations of the same unfolding and to do so in a way that remains compatible with downstream CI manipulations.

Where CHACI is driven by anisotropic coefficient concentration, the second contribution is driven by geometric far-field compressibility of the ERI operator, with the ultimate goal of accelerating MP2 correlation. MP2 provides a widely used description of dynamic correlation as a second-order perturbative correction to the Hartree--Fock reference. Although MP2 is cheaper than higher-level coupled-cluster methods, canonical formulations still involve expensive contractions and are heavily constrained by ERI storage and transformation. The approach developed in this dissertation targets the spin-opposite-scaled variant (SOS-MP2), which focuses on opposite-spin (Coulomb-like) contributions and is particularly amenable to atomic-orbital formulations. The central idea is to represent the reshaped ERI tensor as an H$^2$ matrix, leveraging a near-/far-field split: near-field blocks (including diagonal and nearby interactions) are handled explicitly or with mild compression, while far-field blocks are represented in low rank with nested bases to maximize reuse across the hierarchy. This hierarchical ERI representation is then coupled to an AO Laplace-transform formulation of SOS-MP2, in which the correlation energy is expressed as a weighted sum over quadrature points. At each quadrature node, the computation reduces to applying the ERI operator to structured auxiliary quantities constructed from energy-weighted density-like matrices. These auxiliary matrices exhibit additional sparsity in large finite systems due to spatial decay; by truncating small elements below a user tolerance and storing them in sparse formats (e.g., CSR), the algorithm restricts work to the chemically relevant entries while still accounting for the long-range contributions through the compressed ERI operator rather than discarding them. A further organizational feature is a short-/long-range decomposition of the ERI operator within the hierarchical format, enabling separate index transformations for near-field and far-field contributions and an efficient recombination in the trace expressions that define the SOS-MP2 energy. In this way, the method replaces dense tensor contractions by hierarchical operator applications and small dense kernels, with accuracy controlled by local block tolerances and rank adaptivity in the H$^2$ representation together with quadrature parameters in the Laplace factorization. The overarching outcome is a correlation pipeline whose dominant stages are governed by hierarchy traversal and nested-basis arithmetic rather than by unstructured dense algebra.

Taken together, the two methods illustrate a coherent design philosophy for hierarchical compression in post-HF electronic structure: (i) identify the dominant structural regularity of the target object, (ii) select or develop a hierarchical format whose partitioning strategy aligns with that regularity, and (iii) embed local error control into the representation and kernels so that accuracy is achieved through interpretable tolerances rather than through ad hoc global heuristics. CHACI emphasizes that, for wavefunction objects, the correct notion of ``near field'' may be an information-theoretic region (a corner of high coefficient density) rather than a geometric one, and that reordering and blockwise rank selection are essential for turning empirical concentration into reliable memory savings. The H$^2$-AO-SOS-MP2 pipeline emphasizes that, for operator objects such as ERIs, geometric locality and far-field low rank can be exploited most effectively when nested bases are reused across levels and when the surrounding correlation algorithm is reformulated so that its dominant operations become repeated applications of the compressed operator.

The dissertation is organized to develop these contributions from a shared foundation and to connect their design choices to reproducible computational benefits. We begin with preliminaries that establish the hierarchical-matrix background needed throughout, including hierarchical partitioning, admissibility concepts, blockwise low-rank approximation, nested bases in H$^2$ formats, and the primitives for compression, traversal, and error control. We also summarize the electronic-structure context required to situate the two compression targets, including the organization of CI coefficient tensors via $\alpha$--$\beta$ string decompositions and the reshaping of ERIs into pair-space operators. Building on these preliminaries, we first present the CHACI method for compressing FCI (and related active-space CI) coefficient tensors: the corner-hierarchical format, the sorting and normalization procedures, the adaptive rank-selection strategy based on information density, and numerical studies that demonstrate favorable storage--accuracy trade-offs as active spaces grow. We then present the H$^2$-AO-SOS-MP2 method for ERI compression and MP2 acceleration: the H$^2$ data structures and near-/far-field split, the AO Laplace formulation, the sparse treatment of auxiliary matrices, the hierarchical index transformations, and the resulting complexity and accuracy behavior. Finally, we conclude by synthesizing the two contributions under a unified viewpoint: hierarchical compression is most effective when the representation is matched to the geometry of information in the object being approximated---corner concentration for CI coefficients and far-field low rank for ERIs---and when local error control is integrated into the computational pipeline so that chemical accuracy can be reached with predictable resource usage.